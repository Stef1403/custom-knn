{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Custom K-NN implementation \n",
    "A k-nn algorithm that can:\n",
    "1. Handle missing values\n",
    "2. Handle class imbalance \n",
    "3. Handle different scales of data \n",
    "4. Automatically picks the best value for k \n",
    "5. Is close to the same speed as sklearn's \n",
    "6. Should run in parralel\n",
    "7. Regression or Classification \n",
    "\n",
    "## Planning \n",
    "1. Basic implementation \n",
    "2. First get it to run faster with the optimisations\n",
    "3. Just use simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, r2_score, recall_score\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Knn(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A custom k-nearest neighbors (KNN) classifier and regressor that handles missing values.\n",
    "    \n",
    "    Parameters:\n",
    "    - neighbors (int): Number of nearest neighbors to consider.\n",
    "    - optimise (bool): Whether to optimize hyperparameters.\n",
    "    - method (str): 'c' for classification, 'r' for regression.\n",
    "    \"\"\"\n",
    "    def __init__(self, neighbors=None, optimise=False, method='c', imbalance=False):\n",
    "        self.neighbors = neighbors\n",
    "        self.optimise = optimise\n",
    "        self.method = method\n",
    "        self.imbalance = imbalance\n",
    "        self.label_type_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the model with training data.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (array-like): Training feature matrix.\n",
    "        - y (array-like): Target values.\n",
    "        \"\"\"\n",
    "        self.X_ = np.array(X)\n",
    "        type_of_values = self.get_first_non_none_type(y)\n",
    "        if self.method == 'r': \n",
    "            if len(y) == 0:\n",
    "                z = 1\n",
    "            if issubclass(type_of_values, np.floating):\n",
    "                self.label_type_ = float\n",
    "            elif issubclass(type_of_values, np.str_):\n",
    "                self.label_type_ = str\n",
    "                #check if fails\n",
    "            elif issubclass(type_of_values, np.bool_):\n",
    "                self.method = 'c'\n",
    "            else:\n",
    "                self.label_type_ = float\n",
    "            \n",
    "            self.y_ = np.array(y, dtype=float)\n",
    "        else: \n",
    "            if issubclass(type_of_values, np.integer):\n",
    "                print(\"int\")\n",
    "                self.label_type_ = int\n",
    "            elif issubclass(type_of_values, np.bool_):\n",
    "                self.label_type_ = bool\n",
    "            else:\n",
    "                self.label_type_ = str\n",
    "            self.y_ = self._format_labels(y)\n",
    "\n",
    "            \n",
    "        self.masks_ = self._compute_masks(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict target values for the given input data.\n",
    "        \n",
    "        Parameters:\n",
    "        - X (array-like): Input feature matrix.\n",
    "        \n",
    "        Returns:\n",
    "        - list: Predicted values.\n",
    "        \"\"\"\n",
    "        X = np.array(X)\n",
    "        self.test_mask_ = self._compute_masks(X)\n",
    "        if self.method == 'c':\n",
    "            predictions = [self._predict_single_classification(x, test_mask) for x, test_mask in zip(X, self.test_mask_)]\n",
    "        else:\n",
    "            predictions = [self._predict_single_regression(x, test_mask) for x, test_mask in zip(X, self.test_mask_)]\n",
    "        return [self.label_type_(pred) for pred in predictions]\n",
    "    \n",
    "    def _predict_single_regression(self, x, test_mask):\n",
    "        \"\"\"\n",
    "        Predict a single regression instance.\n",
    "        \"\"\"\n",
    "        distances = [self._distance(x, x_train, train_mask, test_mask) for x_train, train_mask in zip(self.X_, self.masks_)]\n",
    "        nearest_neigbor_indices = sorted(range(len(distances)), key=lambda sub: distances[sub])[:self.neighbors]\n",
    "        pred = self._mean([self.y_[index] for index in nearest_neigbor_indices])\n",
    "        return pred\n",
    "\n",
    "    def _predict_single_classification(self, x, test_mask):\n",
    "        \"\"\"\n",
    "        Predict a single classification instance.\n",
    "        \"\"\"\n",
    "        distances = [self._distance(x, x_train, train_mask, test_mask) for x_train, train_mask in zip(self.X_, self.masks_)]\n",
    "        nearest_neigbor_indices = sorted(range(len(distances)), key=lambda sub: distances[sub])[:self.neighbors]\n",
    "        if self.imbalance: \n",
    "            pred = self._sheppards_method(distances=[distances[index] for index in nearest_neigbor_indices], labels=[self.y_[index] for index in nearest_neigbor_indices])\n",
    "        else: pred = self._mode([self.y_[index] for index in nearest_neigbor_indices])\n",
    "        return pred\n",
    "    \n",
    "    def _distance(self, a, b, train_mask, test_mask):\n",
    "        \"\"\"\n",
    "        Compute Euclidean distance between two feature vectors, considering masks.\n",
    "        \"\"\"\n",
    "        mask = train_mask & test_mask\n",
    "        if not np.any(mask): #If there are no values for which both observations have valid values return a big value\n",
    "            return np.inf\n",
    "        diff = (a[mask] - b[mask]) ** 2\n",
    "        return np.sqrt(np.sum(diff))\n",
    "    \n",
    "    def _mean(self, ls):\n",
    "        \"\"\"\n",
    "        Compute the mean of a list.\n",
    "        \"\"\"\n",
    "        return sum(ls) / len(ls)\n",
    "    \n",
    "    def _mode(self, ls):\n",
    "        \"\"\"\n",
    "        Compute the most common value in a list.\n",
    "        \"\"\"\n",
    "        return collections.Counter(ls).most_common()[0][0]\n",
    "    \n",
    "    def _sheppards_method(self, distances, labels):\n",
    "        \"\"\"\n",
    "        Apply Sheppard's method to perform weighted voting based on inverse distances.\n",
    "        \n",
    "        Parameters:\n",
    "        - distances (list of float): Distances of neighbors to the query point.\n",
    "        - labels (list): Corresponding class labels of the neighbors.\n",
    "        \n",
    "        Returns:\n",
    "        - predicted_class: The class with the highest weighted vote.\n",
    "        \"\"\"\n",
    "        weights = 1 / (np.array(distances) + 1e-5)\n",
    "        weighted_votes = {}\n",
    "        for label, weight in zip(labels, weights):\n",
    "            label = str(label)\n",
    "            if label in weighted_votes:\n",
    "                weighted_votes[label] += weight\n",
    "            else:\n",
    "                weighted_votes[label] = weight\n",
    "        \n",
    "        predicted_class = max(weighted_votes, key=weighted_votes.get)\n",
    "        return predicted_class\n",
    "    \n",
    "    def _compute_masks(self, values):\n",
    "        \"\"\"\n",
    "        Compute boolean masks to identify non-missing values.\n",
    "        \"\"\"\n",
    "        return ~pd.isna(values)\n",
    "    \n",
    "    def _format_labels(self, y):\n",
    "        if isinstance(y, pd.Series):  # Convert Pandas Series to list\n",
    "            y = y.to_numpy()\n",
    "        elif isinstance(y, np.ndarray):  # Convert NumPy array to list\n",
    "            y = y.tolist()\n",
    "        elif not isinstance(y, list):\n",
    "            raise ValueError(\"Input y should be a list, NumPy array, or Pandas Series.\")\n",
    "\n",
    "        return list(map(str, y))  # Convert all labels to string\n",
    "    \n",
    "    def get_first_non_none_type(self, lst):\n",
    "        for item in lst:\n",
    "            if item is not None:  # Skip None values\n",
    "                return type(item)\n",
    "        return False  # If only None values are present\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: [50 50]\n",
      "Imbalanced class distribution: [50 50]\n"
     ]
    }
   ],
   "source": [
    "# Generate classification dataset\n",
    "X, y = make_classification(n_samples=100, n_features=5, n_informative=4, \n",
    "                           n_redundant=0, n_classes=2, random_state=42)\n",
    "# Introduce missing values\n",
    "missing_fraction = 0.05  # 5% missing values\n",
    "num_missing = int(missing_fraction * X.size)\n",
    "\n",
    "# Randomly select indices to introduce NaNs\n",
    "np.random.seed(42)  # For reproducibility\n",
    "missing_indices = np.random.choice(X.size, num_missing, replace=False)\n",
    "\n",
    "# Flatten X, introduce NaNs, and reshape back\n",
    "X_flattened = X.flatten()\n",
    "X_flattened[missing_indices] = np.nan\n",
    "X = X_flattened.reshape(X.shape)\n",
    "\n",
    "# Introduce class imbalance by resampling\n",
    "def introduce_class_imbalance(X, y, majority_class_ratio=0.8):\n",
    "    # Get indices of both classes\n",
    "    class_0_indices = np.where(y == 0)[0]\n",
    "    class_1_indices = np.where(y == 1)[0]\n",
    "\n",
    "    # Introduce imbalance by keeping only a fraction of one class\n",
    "    np.random.seed(42)\n",
    "    if len(class_0_indices) > len(class_1_indices):\n",
    "        class_0_indices = np.random.choice(class_0_indices, int(len(class_0_indices) * majority_class_ratio), replace=True)\n",
    "    else:\n",
    "        class_1_indices = np.random.choice(class_1_indices, int(len(class_1_indices) * majority_class_ratio), replace=True)\n",
    "\n",
    "    # Combine the new indices\n",
    "    selected_indices = np.concatenate([class_0_indices, class_1_indices])\n",
    "\n",
    "    # Subset the data\n",
    "    X_imbalanced = X[selected_indices]\n",
    "    y_imbalanced = y[selected_indices]\n",
    "\n",
    "    return X_imbalanced, y_imbalanced\n",
    "\n",
    "# Introduce class imbalance (e.g., 80% of majority class remains)\n",
    "X_imbalanced, y_imbalanced = introduce_class_imbalance(X, y, majority_class_ratio=1)\n",
    "\n",
    "y = list(map(str, y))\n",
    "y_imbalanced = list(map(str, y_imbalanced))\n",
    "# Print class distribution before and after imbalance\n",
    "print(\"Original class distribution:\", np.bincount(y))\n",
    "print(\"Imbalanced class distribution:\", np.bincount(y_imbalanced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg, y_reg = make_regression(n_samples=100, n_features=5, n_informative=5)\n",
    "missing_fraction = 0.05  # 10% missing values\n",
    "\n",
    "# Calculate number of missing values\n",
    "num_missing = int(missing_fraction * X_reg.size)\n",
    "\n",
    "# Randomly select indices to introduce NaNs\n",
    "np.random.seed(42)  # For reproducibility\n",
    "missing_indices = np.random.choice(X_reg.size, num_missing, replace=False)\n",
    "\n",
    "# Flatten X, introduce NaNs, and reshape back\n",
    "X_flattened = X_reg.flatten()\n",
    "X_flattened[missing_indices] = np.nan\n",
    "X_reg = X_flattened.reshape(X_reg.shape)\n",
    "y_reg = list(map(str, y_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "1. sklearn model format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_knn_class = Custom_Knn(neighbors=5, method='c')\n",
    "c_knn_class_imbalance_not_set = Custom_Knn(neighbors=5, method='c')\n",
    "c_knn_class_imbalance = Custom_Knn(neighbors=5, method='c', imbalance=True)\n",
    "c_knn_regg = Custom_Knn(neighbors=1, method='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_knn_regg.fit(X_reg, y_reg)\n",
    "c_knn_class.fit(X, y)\n",
    "c_knn_class_imbalance.fit(X_imbalanced, y_imbalanced)\n",
    "c_knn_class_imbalance_not_set.fit(X_imbalanced, y_imbalanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_regg = c_knn_regg.predict(X=X_reg)\n",
    "\n",
    "pred_class = c_knn_class.predict(X=X)\n",
    "\n",
    "pred_class_imbalance = c_knn_class_imbalance.predict(X=X_imbalanced)\n",
    "\n",
    "pred_class_imbalance_not_set = c_knn_class_imbalance_not_set.predict(X=X_imbalanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_knn_class.label_type_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y, pred_class))\n",
    "\n",
    "print(r2_score(y_reg, pred_regg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'51.7623221029155'"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y, pred_class))\n",
    "print(recall_score(y, pred_class, pos_label='0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.88\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_imbalanced, pred_class_imbalance))\n",
    "print(recall_score(y_imbalanced, pred_class_imbalance, pos_label='0'))\n",
    "\n",
    "print(accuracy_score(y_imbalanced, pred_class_imbalance_not_set))\n",
    "print(recall_score(y_imbalanced, pred_class_imbalance_not_set, pos_label='0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
